<!-- # ğŸš€ starVLA Learning

## ğŸ“– Github Link
https://github.com/starVLA/starVLA

## ğŸ¯ Learning Goals
- [ ] éƒ¨ç½²é¡¹ç›®
- [ ] è·‘é€šliberoå¿«é€Ÿæµ‹è¯„
...

### âœ… Completed
- [âˆš] Environment setup and StarVLA deployment
- [âˆš] è·‘é€šlibero_spatialæµ‹è¯„

## ğŸ› ï¸ å›°éš¾ä¸è§£å†³æ–¹æ¡ˆ
1. æŠ¥é”™ï¼šValueError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: Flash Attention 2 is not available on CPU. Please make sure torch can access a CUDA device.
å¯èƒ½æ˜¯accelerateä¸torchç¯å¢ƒä¸é…å¥—ï¼Œä¸‹é¢æ˜¯ä¸€å¥—å¯ä»¥è·‘é€šä»£ç çš„ç¯å¢ƒã€‚

pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
æ£€éªŒï¼š
python -c "import torch; print('CUDAå¯ç”¨:' , torch.cuda.is_available()); print('å½“å‰ç‰ˆæœ¬:', torch.version.cuda); print('è®¾å¤‡åç§°:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'æ— ')"

pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
æ£€éªŒï¼špython -c "import torch; from flash_attn import flash_attn_func; print('FlashAttention éªŒè¯æˆåŠŸï¼')"

grep -vE "torch|torchvision" requirements.txt > requirements_new.txt    # 1. è¿‡æ»¤åˆ°æ–°æ–‡ä»¶
pip install -r requirements_new.txt    # 2. å®‰è£…è¿‡æ»¤åçš„ä¾èµ–
æ£€éªŒï¼š
python -c "from accelerate import Accelerator; print(Accelerator().device)"
accelerate test

pip install -e .

2. æŠ¥é”™ï¼šRuntimeError: Cannot access accelerator device when none is available.
å¿˜è®°ä¿®æ”¹run_policy_server.shä¸­çš„gpu_idäº†ã€‚æ ¹æ®è‡ªå·±æœåŠ¡å™¨ä¸Šå¸Œæœ›ç”¨çš„gpuç¼–å·å»ä¿®æ”¹å³å¯ã€‚

3. run_policy_server.shç¯å¢ƒä¿®æ”¹
export gpu_id=0    # ä½¿ç”¨ç¬¬0å·GPU
export star_vla_python=/mnt/16T/wangyunda/miniconda3/envs/starVLA/bin/python    # è®¾ç½®starVLAç¯å¢ƒ
your_ckpt=/mnt/16T/wangyunda/starVLA/Qwen2.5-VL-GR00T-LIBERO-4in1/checkpoints/steps_30000_pytorch_model.pt    #æ¨¡å‹æƒé‡è·¯å¾„

## ğŸ”¬ Experiment Results
è§†é¢‘æ–‡ä»¶å­˜å‚¨åœ¨ ~/starVLA/results/libero_spatialä¸­ï¼Œè®­ç»ƒæ—¥å¿—å­˜å‚¨åœ¨ ~/starVLA/logs/20260207_233945/output.logä¸­ã€‚
<video src="/mnt/16T/wangyunda/starVLA/results/libero_spatial/Qwen2.5-VL-GR00T-LIBERO-4in1_checkpoints_steps_30000_pytorch_model.pt/rollout_pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate_episode0_success.mp4" controls width="100%"></video> -->

# ğŸš€ starVLA Learning Report

> **é¡¹ç›®ä»“åº“**: [ğŸ”— starVLA/starVLA](https://github.com/starVLA/starVLA)  
> **è®°å½•æ—¶é—´**: 2026-02-08

---

## ğŸ¯ å­¦ä¹ ç›®æ ‡ (Learning Goals)

- [x] **ç¯å¢ƒéƒ¨ç½²**ï¼šå®ŒæˆåŸºç¡€ç¯å¢ƒæ­å»ºä¸ StarVLA éƒ¨ç½²
- [x] **å¿«é€Ÿæµ‹è¯„**ï¼šè·‘é€š `libero_spatial` æµ‹è¯„æµç¨‹
- [ ] **æ·±åº¦ç ”ç©¶**ï¼šåˆ†æä¸åŒ Checkpoints åœ¨ä¸åŒä»»åŠ¡ä¸‹çš„è¡¨ç°
- [ ] **è‡ªå®šä¹‰è®­ç»ƒ**ï¼šå°è¯•å¾®è°ƒæ¨¡å‹å‚æ•°

---

## ğŸ› ï¸ å›°éš¾ä¸è§£å†³æ–¹æ¡ˆ (Troubleshooting)

### 1. FlashAttention 2 ä¸è®¾å¤‡ä¸åŒ¹é…
> **æŠ¥é”™ä¿¡æ¯**ï¼š`ValueError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: Flash Attention 2 is not available on CPU.`

**ğŸ’¡ æ ¹æœ¬åŸå› **ï¼š`accelerate` åº“æ— æ³•è¯†åˆ« GPUï¼Œæˆ– `torch` ä¸ `flash-attention` ç‰ˆæœ¬ä¸å…¼å®¹ã€‚

**âœ… è§£å†³æ–¹æ¡ˆï¼ˆç»éªŒè¯çš„ç¨³å®šç¯å¢ƒï¼‰**ï¼š

1. **é‡æ–°å®‰è£…æ ¸å¿ƒé©±åŠ¨ä¸ Torch**ï¼š
   ```bash
   pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)

```

2. **å®‰è£…é€‚é…çš„ FlashAttention äºŒè¿›åˆ¶åŒ…**ï¼š
```bash
pip install [https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl](https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl)

```


3. **è¿‡æ»¤å¹¶å®‰è£…å…¶ä½™ä¾èµ–**ï¼š
```bash
# è¿‡æ»¤æ‰å·²æ‰‹åŠ¨å®‰è£…çš„ torch ä¾èµ–ï¼Œé¿å…å†²çª
grep -vE "torch|torchvision" requirements.txt > requirements_new.txt
pip install -r requirements_new.txt
pip install -e .

```



**ğŸ” ç¯å¢ƒéªŒè¯è¡¨**ï¼š

| æ£€æŸ¥é¡¹ | éªŒè¯å‘½ä»¤ | é¢„æœŸè¾“å‡º |
| --- | --- | --- |
| **CUDA å¯ç”¨æ€§** | `python -c "import torch; print(torch.cuda.is_available())"` | `True` |
| **FlashAttn** | `python -c "from flash_attn import flash_attn_func"` | `(æ— æŠ¥é”™)` |
| **Accelerate** | `accelerate test` | `Passed` |

---

### 2. æ˜¾å¡è®¾å¤‡è®¿é—®å¤±è´¥ (RuntimeError)

> **æŠ¥é”™ä¿¡æ¯**ï¼š`RuntimeError: Cannot access accelerator device when none is available.`

**ğŸ“ ä¿®æ­£æ–¹æ³•**ï¼šæ£€æŸ¥å¹¶ä¿®æ”¹ `run_policy_server.sh` ä¸­çš„ç¯å¢ƒå˜é‡ï¼š

* **GPU ID**: ç¡®ä¿ `export gpu_id=0` ä¸å½“å‰æœåŠ¡å™¨ç©ºé—²æ˜¾å¡ç¼–å·ä¸€è‡´ã€‚
* **è·¯å¾„æ£€æŸ¥**: ç¡®ä¿ `your_ckpt` æŒ‡å‘äº†æ­£ç¡®çš„ `.pt` æ–‡ä»¶ç»å¯¹è·¯å¾„ã€‚

```bash
# ä¿®æ”¹ç¤ºä¾‹
export gpu_id=0 
export star_vla_python=/mnt/16T/wangyunda/miniconda3/envs/starVLA/bin/python 
your_ckpt=/mnt/16T/wangyunda/starVLA/Qwen2.5-VL-GR00T-LIBERO-4in1/checkpoints/steps_30000_pytorch_model.pt

```

---

## ğŸ”¬ å®éªŒç»“æœå±•ç¤º (Experiment Results)

### ğŸ“Š æ–‡ä»¶è·¯å¾„è¯´æ˜

* **è§†é¢‘å­˜å‚¨**: `~/starVLA/results/libero_spatial`
* **è®­ç»ƒæ—¥å¿—**: `~/starVLA/logs/20260207_233945/output.log`

### ğŸ“¹ Rollout æ¼”ç¤º

**ä»»åŠ¡æè¿°**ï¼š*Pick up the black bowl between the plate and the ramekin and place it on the plate*

<div align="center">
<table style="border: none; background-color: transparent;">
<tr>
<td align="center" style="border: none;">
<video src="VLA-Learning/notes/project/rollout_pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate_episode0_success.mp4"
controls
width="100%"
style="border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.3);">
æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒ HTML5 è§†é¢‘æ’­æ”¾ã€‚
</video>
<p style="margin-top: 10px; color: #666;">
<b>ğŸ¥ åœºæ™¯æ¼”ç¤ºï¼šæŠ“å–é»‘ç¢—å¹¶ç²¾å‡†æ”¾ç½® (Episode 0 - Success)</b>
</p>
</td>
</tr>
</table>
</div>

---

```



